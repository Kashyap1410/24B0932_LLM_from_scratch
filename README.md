# Building a Custom GPT From Scratch
This project is part of the Summer of Code (SOC) 2025 @ IIT Bombay, under the mentorship of Yashwanth VVS and co-mentors Gnana Mahesh and Jasmitha.

### Description
This repository aims to build a miniature GPT-style language model from the ground up using Python and PyTorch.

Through this, I aim to understand the core building blocks of modern LLMs, implement every component of LLMs in Python & PyTorch, pretrain the model on raw text and fine‑tune it further on both classification and instruction following tasks.

The reference for this project would be the "Building a Large Language Model (From Scratch)" book by Sebastian Raschka.

### Project Timeline
| Week | Goal                                                          |
| ---- | ------------------------------------------------------------- |
| 1    | PyTorch basics & Notebook setup                               |
| 2    | Tokenization & Data pipeline                                  |
| 3–4  | Attention mechanism, Transformer block, Full GPT architecture |
| 5–6  | Pretraining on raw text                                       |
| 7    | Fine-tuning for classification                                |
| 8    | Fine-tuning for instruction-following                         |
